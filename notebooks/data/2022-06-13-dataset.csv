General Information,,,,,,,,Experimentation Progress (Preliminary Results),,,,"Qualitative Inspection 
(do the spans contain...)",,Span Characteristics,,,,,
Name,Brief Description,Related Paper,Data URL,Year,Domain,Language,License,ner,spancat,BERT + CRF,Has .spacy files?,Noun phrases?,Nested entities?,Avg. Span Length,"(Min, Max) Length",Span Distinctiveness,Boundary Distinctiveness,Num. Labels,Span Types
ANeM,Anatomical Entity Mention (AnEM) training corpus containing abstracts and full-text biomedical papers ,Open-domain Antomical Entity Mention Detection (ACL 2012),https://github.com/juand-r/entity-recognition-datasets,2012,Biomed,en,,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,1.34,"(1, 11)",4.78,1.84,11,"Multi-tissue_structure, Organism substance, Organ, Cell, Tissue"
BTC,"Broad Twiter Corpus (BTC) containing a list of tweets. Here, I'm using the full UK language dataset",Broad Twitter Corpus: A Diverse Named Entity Recognition Resource,https://github.com/juand-r/entity-recognition-datasets,2016,Social Media,en,,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,1.31,"(1, 5)",3.67,1.66,3,"PER, ORG, LOC"
SEC Filings,Contains SEC Filings from various companies,Domain Adaption of Named Entity Recognition to Support Credit Risk Assessment,https://github.com/juand-r/entity-recognition-datasets,2015,Finance,en,,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,1.20,"(1, 8)",4.02,1.23,4,"PER, ORG, MISC, LOC"
Wikigold,Dataset of selected texts from Wikipedia,Named Entity Recognition in Wikipedia,https://github.com/juand-r/entity-recognition-datasets,2009,Wikipedia,en,,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,1.58,"(1, 13)",2.64,1.12,4,"PER, ORG, MISC, LOC"
WikiNeural (de),Larger Wikipedia dataset from a more recent paper,WikiNEuRal: Combined Neural and Knowledge-based Silver Data Creation for Multilingual NER,https://github.com/juand-r/entity-recognition-datasets,2021,Wikipedia,de,,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,1.31,"(1, 18)",3.47,1.19,4,"PER, ORG, MISC, LOC"
WikiNeural (en),Larger Wikipedia dataset from a more recent paper,WikiNEuRal: Combined Neural and Knowledge-based Silver Data Creation for Multilingual NER,https://github.com/juand-r/entity-recognition-datasets,2021,Wikipedia,en,,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,1.34,"(1, 10)",2.79,1.26,4,"PER, ORG, MISC, LOC"
WikiNeural (es),Larger Wikipedia dataset from a more recent paper,WikiNEuRal: Combined Neural and Knowledge-based Silver Data Creation for Multilingual NER,https://github.com/juand-r/entity-recognition-datasets,2021,Wikipedia,es,,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,1.50,"(1, 17)",2.52,1.11,4,"PER, ORG, MISC, LOC"
WikiNeural (nl),Larger Wikipedia dataset from a more recent paper,WikiNEuRal: Combined Neural and Knowledge-based Silver Data Creation for Multilingual NER,https://github.com/juand-r/entity-recognition-datasets,2021,Wikipedia,nl,,TRUE,TRUE,FALSE,TRUE,FALSE,FALSE,1.34,"(1, 9)",3.24,1.22,4,"PER, ORG, MISC, LOC"
WNUT17,"Focuses on identifying unusual, previously-unseen entities in the context of emerging discussions",Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition,https://github.com/juand-r/entity-recognition-datasets,2017,Social Media,multi,,TRUE,TRUE,FALSE,TRUE,TRUE,FALSE,1.42,"(1, 14)",3.95,1.74,6,"location, group, corporation, person, creative-work, product"
ACE2004,,,https://catalog.ldc.upenn.edu/LDC2005T09,2004,,,,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,,,,,,
ACE2005,,,https://catalog.ldc.upenn.edu/LDC2006T06,2005,,,,FALSE,FALSE,FALSE,FALSE,FALSE,TRUE,,,,,7,
GENIA,,,,,Biomed,,,FALSE,FALSE,FALSE,TRUE,FALSE,TRUE,2.36,"(1, 26)",1.45,0.71,36,"DNA, protein, cell_line, cell_type"
CoNLL 2003,,,https://aclanthology.org/W03-0419/,2003,News,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,4,
CLEF,,https://hal.archives-ouvertes.fr/hal-03369846/file/CLEF_eHealth_21___LNCS_Overview.pdf,https://clefehealth.imag.fr/?page_id=215,,,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,,
OntoNotes5,,,https://catalog.ldc.upenn.edu/LDC2013T19,2013,General,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,18,
GUM,,,,,,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,,
Re3d,,,https://github.com/dstl/re3d,,Defense,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,10,
FiNER,a dataset of 1.1M sentences with gold xbrl tags (financial domain),https://arxiv.org/pdf/2203.06482.pdf,https://huggingface.co/datasets/nlpaueb/finer-139,2022,Financial,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,139,
BC5CDR,,,,,Biomed,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,2,"chemical, disease"
NNE,"a fine-grained, nested named entity dataset over the full Wall Street Journal portion of the Penn Treebank (PTB). Our annotation comprises 279,795 mentions of 114 entity types with up to 6 layers of nesting. We hope the public release of this large dataset for English newswire will encourage development of new techniques for nested NER.",NNE: A Dataset for Nested Named Entity Recognition in English Newswire,,,,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,,
toxic spans,Update from the SemEval 2021 dataset,From the Detection of Toxic Spans in Online Discussions to the Analysis of Toxic-to-Civil Transfer,https://github.com/ipavlopoulos/toxic_spans/tree/master/ACL2022,2022,,,CC0,TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,1.09,"(1, 21)",2.97,0.84,5,"insult, threat, profane-obscene, other  toxicity, identify based attack"
Few-NERD,a large-scale human-annotated few-shot NER dataset with a hierarchy of 8 coarse-grained and 66 fine-grained entity types,FEW-NERD: A Few-shot Named Entity Recognition Dataset,https://ningding97.github.io/fewnerd/,2021,,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,8 (66),
SCIERC,a dataset that includes annotations for all three tasks and develop a unified framework called Scientific Information Extractor (SciIE) for with shared span representations.,"Multi-Task Identification of Entities, Relations, and Coreference for Scientific Knowledge Graph Construction",http://nlp.cs.washington.edu/sciIE/,2018,Scientific,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,6,"Task, Method, Metric, Material, Other-Scientific-Term, Generic"
PDNC,"C, an annotated dataset of quotations for English literary texts. PDNC contains annotations for 35,978 quotations across 22 full-length novels, and is by an order of magnitude the largest corpus of its kind. Each quotation is annotated for the speaker, addressees, type of quotation, referring expression, and character mentions within the quotation text. The annotated attributes allow for a comprehensive evaluation of models of quotation attribution and coreference for literary texts",The Project Dialogism Novel Corpus: A Dataset for Quotation Attribution in Literary Texts,https://github.com/priya22/pdnc-lrec2022,2022,Literature,,,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE,,,,,,
,,,,,,,,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,,,,,,